{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.preview in file CCB_plot_style_0v4.mplstyle, line 55 ('text.latex.preview  : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file CCB_plot_style_0v4.mplstyle, line 63 ('mathtext.fallback_to_cm : True ## When True, use symbols from the Computer Modern fonts')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from os.path import join\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from scipy import stats\n",
    "import xgboost as xgb\n",
    "#from hyperopt import fmin, tpe, hp, Trials, rand\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import matplotlib as mpl\n",
    "plt.style.use('CCB_plot_style_0v4.mplstyle')\n",
    "c_styles      = mpl.rcParams['axes.prop_cycle'].by_key()['color']   #fetch the defined color styles\n",
    "high_contrast = ['#004488', '#DDAA33', '#BB5566', '#000000'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading training, validation, and test data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Loading data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26701, 6282)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = [\"MEKEDQEKTGKLTLVLALATFLAAFGSSFQYGYNVAAVNSPSEFMQQFYNDTYYDRNKENIESFTLTLLWSLTVSMFPFGGFIGSLMVGFLVNNLGRKGALLFNNIFSILPAILMGCSKIAKSFEIIIASRLLVGICAGISSNVVPMYLGELAPKNLRGALGVVPQLFITVGILVAQLFGLRSVLASEEGWPILLGLTGVPAGLQLLLLPFFPESPRYLLIQKKNESAAEKALQTLRGWKDVDMEMEEIRKEDEAEKAAGFISVWKLFRMQSLRWQLISTIVLMAGQQLSGVNAIYYYADQIYLSAGVKSNDVQYVTAGTGAVNVFMTMVTVFVVELWGRRNLLLIGFSTCLTACIVLTVALALQNTISWMPYVSIVCVIVYVIGHAVGPSPIPALFITEIFLQSSRPSAYMIGGSVHWLSNFIVGLIFPFIQVGLGPYSFIIFAIICLLTTIYIFMVVPETKGRTFVEINQIFAKKNKVSDVYPEKEEKELNDLPPATREQ\",\n",
    "            \"MSNKQETKILGMPPFVVDFLMGGVSAAVSKTAAAPIERIKLLVQNQDEMIKAGRLDRRYNGIIDCFRRTTADEGLMALWRGNTANVIRYFPTQALNFAFRDKFKAMFGYKKDKDGYAKWMAGNLASGGAAGATSLLFVYSLDYARTRLANDAKSAKGGGARQFNGLIDVYRKTLASDGIAGLYRGFGPSVAGIVVYRGLYFGMYDSIKPVVLVGPLANNFLASFLLGWCVTTGAGIASYPLDTVRRRMMMTSGEAVKYKSSIDAFRQIIAKEGVKSLFKGAGANILRGVAGAGVLSIYDQLQILLFGKAFKGGSG\",\n",
    "            ]\n",
    "\n",
    "data_train = pd.read_pickle(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"df_UID_MID_train.pkl\"))\n",
    "data_test = pd.read_pickle(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"df_UID_MID_test.pkl\"))\n",
    "\n",
    "data_train = data_train.loc[~data_train[\"Sequence\"].isin(sequences)]\n",
    "\n",
    "data_train.reset_index(inplace = True, drop = True)\n",
    "data_test.reset_index(inplace = True, drop = True)\n",
    "\n",
    "len(data_train), len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''df_train = pd.read_pickle(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\",  \"df_train.pkl\"))\n",
    "df_seq = pd.DataFrame({\"Sequence\" : df_train[\"Sequence\"], \"cluster\" : df_train[\"cluster\"]})\n",
    "df_seq.drop_duplicates(inplace = True)\n",
    "data_train = data_train.merge(df_seq, on = \"Sequence\", how = \"left\")\n",
    "data_train.head()\n",
    "\n",
    "all_clusters_train = list(set(data_train[\"cluster\"]))\n",
    "random.shuffle(all_clusters_train)\n",
    "n = len(all_clusters_train)\n",
    "k = int(n/5)\n",
    "clusters_fold1, clusters_fold2, clusters_fold3 = all_clusters_train[:k], all_clusters_train[k:k*2], all_clusters_train[k*2:k*3]\n",
    "clusters_fold4, clusters_fold5= all_clusters_train[k*3:4*k], all_clusters_train[4*k:]\n",
    "\n",
    "fold_indices = [list(data_train.loc[data_train[\"cluster\"].isin(clusters_fold1)].index),\n",
    "                list(data_train.loc[data_train[\"cluster\"].isin(clusters_fold2)].index),\n",
    "                list(data_train.loc[data_train[\"cluster\"].isin(clusters_fold3)].index),\n",
    "                list(data_train.loc[data_train[\"cluster\"].isin(clusters_fold4)].index),\n",
    "                list(data_train.loc[data_train[\"cluster\"].isin(clusters_fold5)].index)]\n",
    "\n",
    "\n",
    "\n",
    "train_indices = [[], [], [], [], []]\n",
    "test_indices = [[], [], [], [], []]\n",
    "\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        if i != j:\n",
    "            train_indices[i] = train_indices[i] + fold_indices[j]\n",
    "            \n",
    "    test_indices[i] = fold_indices[i]\n",
    "    \n",
    "    \n",
    "np.save(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"splits\", \"CV_train_indices_SPOT.npy\"), train_indices)\n",
    "np.save(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"splits\", \"CV_test_indices_SPOT.npy\"), test_indices)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.load(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"splits\", \"CV_train_indices_SPOT.npy\"), allow_pickle = True)\n",
    "test_indices = np.load(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\",\"splits\", \"CV_test_indices_SPOT.npy\"), allow_pickle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Input: ECFP /ESM-1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input and output arrays (ECFP /ESM-1b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (int(df[\"outcome\"][ind]), );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = data_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = data_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_neg_mcc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if y == 0 else 1.0 for y in data_train[\"outcome\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    acc = []\n",
    "    mcc = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "        mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "        print(acc)\n",
    "        print(mcc)\n",
    "    return(-np.mean(mcc))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [7,8,9,10,11,12]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.00,0.33)}''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "best = fmin(fn = cross_validation_neg_mcc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = 2000, trials = trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training and validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9387825487152958, 0.936633344082554, 0.9346483363219765, 0.9388050444490387, 0.9417836498761354] [0.9723292698689124, 0.9698668028138591, 0.9713961050348995, 0.9751258428848093, 0.9729684489657655] [0.8373825869216985, 0.8311919955388328, 0.8261618817695867, 0.8379900468162315, 0.8463804689807323]\n",
      "Accuracy on test set: 0.9173829990448902, ROC-AUC score for test set: 0.9565924697505808, MCC: 0.783824315566741\n"
     ]
    }
   ],
   "source": [
    "param = {'learning_rate': 0.27093305483481267,\n",
    "         'max_delta_step': 3.2767682439803796,\n",
    "         'max_depth': 12,\n",
    "         'min_child_weight': 0.2885682036264081,\n",
    "         'num_rounds': 155.7259319282595,\n",
    "         'reg_alpha': 0.7491845522015184,\n",
    "         'reg_lambda': 0.23666994423192977,\n",
    "         'weight': 0.3097321347502892}\n",
    "\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in data_train[\"outcome\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "mcc = []\n",
    "acc = []\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]),\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    roc_auc.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "    \n",
    "print(acc, roc_auc, mcc)\n",
    "acc_cv_esm1b_ecfp = acc\n",
    "mcc_cv_esm1b_ecfp = mcc\n",
    "roc_auc_cv_esm1b_ecfp = roc_auc\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round))#, evallist)\n",
    "\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test_esm1b_ecfp = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc_test_esm1b_ecfp = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc_test_esm1b_ecfp = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test_esm1b_ecfp,\n",
    "                                                                              roc_auc_test_esm1b_ecfp,\n",
    "                                                                              mcc_test_esm1b_ecfp))\n",
    "data_test[\"y_pred_ECFP_ESM1b\"] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Input: ChemBERTa /ESM-1b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input and output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b\"][ind]\n",
    "        ecfp = df[\"ChemBERTa\"][ind]\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (int(df[\"outcome\"][ind]), );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = data_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = data_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(767)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_neg_mcc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if y == 0 else 1.0 for y in data_train[\"outcome\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    acc = []\n",
    "    mcc = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "        mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "        print(acc)\n",
    "        print(mcc)\n",
    "    return(-np.mean(mcc))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [7,8,9,10,11,12]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.00,0.33)}''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "best = fmin(fn = cross_validation_neg_mcc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = 2000, trials = trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training and validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.11211681842630247,\n",
    "         'max_delta_step': 1.6131034337079901,\n",
    "          'max_depth': 11,\n",
    "           'min_child_weight': 4.7767365234160195,\n",
    "            'num_rounds': 103.2995179203733,\n",
    "             'reg_alpha': 1.061445251263431,\n",
    "              'reg_lambda': 0.35852219441242894,\n",
    "               'weight': 0.4063667356577428}\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in data_train[\"outcome\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "mcc = []\n",
    "acc = []\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]),\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    roc_auc.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "    \n",
    "print(acc, roc_auc, mcc)\n",
    "acc_cv_esm1b_chemberta = acc\n",
    "mcc_cv_esm1b_chemberta = mcc\n",
    "roc_auc_cv_esm1b_chemberta = roc_auc\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round),)# evallist)\n",
    "\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test_esm1b_chemberta = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc_test_esm1b_chemberta = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc_test_esm1b_chemberta = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test_esm1b_chemberta,\n",
    "                                                                              roc_auc_test_esm1b_chemberta,\n",
    "                                                                              mcc_test_esm1b_chemberta))\n",
    "data_test[\"y_pred_ChemBERTa_ESM1b\"] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Production mode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.11211681842630247,\n",
    "         'max_delta_step': 1.6131034337079901,\n",
    "          'max_depth': 11,\n",
    "           'min_child_weight': 4.7767365234160195,\n",
    "            'num_rounds': 103.2995179203733,\n",
    "             'reg_alpha': 1.061445251263431,\n",
    "              'reg_lambda': 0.35852219441242894,\n",
    "               'weight': 0.4063667356577428}\n",
    "\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in \n",
    "                    list(data_train[\"outcome\"]) + list(data_test[\"outcome\"])])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "dtrain = xgb.DMatrix(np.concatenate([train_X, test_X]), weight = weights, label = np.concatenate([train_y, test_y]),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round))\n",
    "\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test_esm1b_chemberta = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc_test_esm1b_chemberta = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc_test_esm1b_chemberta = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test_esm1b_chemberta,\n",
    "                                                                              roc_auc_test_esm1b_chemberta,\n",
    "                                                                              mcc_test_esm1b_chemberta))\n",
    "\n",
    "#save model:\n",
    "pickle.dump(bst, open(join(\"..\", \"..\", \"data\", \"xgboost_model_production_mode.dat\"), \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Input: ChemBERTa /ESM-1b_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input and output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ChemBERTa\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (int(df[\"outcome\"][ind]), );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = data_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = data_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(767)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_neg_mcc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if y == 0 else 1.0 for y in data_train[\"outcome\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    acc = []\n",
    "    mcc = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "        mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "        print(acc)\n",
    "        print(mcc)\n",
    "    return(-np.mean(mcc))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [7,8,9,10,11,12]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.00,0.33)}''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a random grid search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "best = fmin(fn = cross_validation_neg_mcc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = 2000, trials = trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training and validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.3529495351679151,\n",
    "         'max_delta_step': 2.807731336260235,\n",
    "         'max_depth': 9,\n",
    "         'min_child_weight': 1.0278675583399608,\n",
    "         'num_rounds': 288.8214233876903,\n",
    "         'reg_alpha': 0.025697406994433236,\n",
    "         'reg_lambda': 1.4540684149025358,\n",
    "         'weight': 0.3262212830421869}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in data_train[\"outcome\"]])\n",
    "\n",
    "\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "mcc = []\n",
    "acc = []\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]),\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    roc_auc.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "    \n",
    "print(acc, roc_auc, mcc)\n",
    "acc_cv_esm1b_ts_chemberta = acc\n",
    "mcc_cv_esm1b_ts_chemberta = mcc\n",
    "roc_auc_cv_esm1b_ts_chemberta = roc_auc\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round))#, evallist)\n",
    "\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test_esm1b_ts_chemberta = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc_test_esm1b_ts_chemberta = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc_test_esm1b_ts_chemberta = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test_esm1b_ts_chemberta,\n",
    "                                                                              roc_auc_test_esm1b_ts_chemberta,\n",
    "                                                                              mcc_test_esm1b_ts_chemberta))\n",
    "data_test[\"y_pred_chemberta_esm1b_ts\"] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Input: ECFP /ESM-1b_ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Creating input and output arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_and_output_data(df):\n",
    "    X = ();\n",
    "    y = ();\n",
    "    \n",
    "    for ind in df.index:\n",
    "        emb = df[\"ESM1b_ts\"][ind]\n",
    "        ecfp = np.array(list(df[\"ECFP\"][ind])).astype(int)\n",
    "                \n",
    "        X = X +(np.concatenate([ecfp, emb]), );\n",
    "        y = y + (int(df[\"outcome\"][ind]), );\n",
    "\n",
    "    return(X,y)\n",
    "\n",
    "train_X, train_y =  create_input_and_output_data(df = data_train)\n",
    "test_X, test_y =  create_input_and_output_data(df = data_test)\n",
    "\n",
    "\n",
    "feature_names =  [\"ECFP_\" + str(i) for i in range(1024)]\n",
    "feature_names = feature_names + [\"ESM1b_\" + str(i) for i in range(1280)]\n",
    "\n",
    "train_X = np.array(train_X)\n",
    "test_X  = np.array(test_X)\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "test_y  = np.array(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) hyperparameter optimization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def cross_validation_neg_mcc_gradient_boosting(param):\n",
    "    num_round = param[\"num_rounds\"]\n",
    "    param[\"tree_method\"] = \"gpu_hist\"\n",
    "    param[\"sampling_method\"] = \"gradient_based\"\n",
    "    param['objective'] = 'binary:logistic'\n",
    "    weights = np.array([param[\"weight\"] if y == 0 else 1.0 for y in data_train[\"outcome\"]])\n",
    "    \n",
    "    del param[\"num_rounds\"]\n",
    "    del param[\"weight\"]\n",
    "    \n",
    "    acc = []\n",
    "    mcc = []\n",
    "    for i in range(5):\n",
    "        train_index, test_index  = train_indices[i], test_indices[i]\n",
    "        dtrain = xgb.DMatrix(np.array(train_X[train_index]), weight = weights[train_index],\n",
    "                         label = np.array(train_y[train_index]))\n",
    "        dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "        bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "        y_valid_pred = np.round(bst.predict(dvalid))\n",
    "        validation_y = train_y[test_index]\n",
    "    \n",
    "        acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "        mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "        print(acc)\n",
    "        print(mcc)\n",
    "    return(-np.mean(mcc))\n",
    "\n",
    "#Defining search space for hyperparameter optimization\n",
    "space_gradient_boosting = {\"learning_rate\": hp.uniform(\"learning_rate\", 0.01, 0.5),\n",
    "    \"max_depth\": hp.choice(\"max_depth\", [7,8,9,10,11,12]),\n",
    "    \"reg_lambda\": hp.uniform(\"reg_lambda\", 0, 5),\n",
    "    \"reg_alpha\": hp.uniform(\"reg_alpha\", 0, 5),\n",
    "    \"max_delta_step\": hp.uniform(\"max_delta_step\", 0, 5),\n",
    "    \"min_child_weight\": hp.uniform(\"min_child_weight\", 0.1, 15),\n",
    "    \"num_rounds\":  hp.uniform(\"num_rounds\", 200, 400),\n",
    "    \"weight\" : hp.uniform(\"weight\", 0.00,0.33)}''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''trials = Trials()\n",
    "\n",
    "best = fmin(fn = cross_validation_neg_mcc_gradient_boosting, space = space_gradient_boosting,\n",
    "                algo = rand.suggest, max_evals = 2000, trials = trials)''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (c) Training and validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'learning_rate': 0.38469669326473216,\n",
    "         'max_delta_step': 1.3916449221275724,\n",
    "         'max_depth': 13,\n",
    "         'min_child_weight': 1.2505348658632713,\n",
    "         'num_rounds': 289.98564856980886,\n",
    "         'reg_alpha': 0.027205529650688454,\n",
    "         'reg_lambda': 1.3723293809191506,\n",
    "         'weight': 0.2776515876001598}\n",
    "\n",
    "num_round = param[\"num_rounds\"]\n",
    "param[\"tree_method\"] = \"gpu_hist\"\n",
    "param[\"sampling_method\"] = \"gradient_based\"\n",
    "param['objective'] = 'binary:logistic'\n",
    "weights = np.array([param[\"weight\"] if binding == 0 else 1.0 for binding in data_train[\"outcome\"]])\n",
    "\n",
    "del param[\"num_rounds\"]\n",
    "del param[\"weight\"]\n",
    "\n",
    "mcc = []\n",
    "acc = []\n",
    "roc_auc = []\n",
    "for i in range(5):\n",
    "    train_index, test_index  = train_indices[i], test_indices[i]\n",
    "    dtrain = xgb.DMatrix(np.array(train_X[train_index]),\n",
    "                     label = np.array(train_y[train_index]))\n",
    "    dvalid = xgb.DMatrix(np.array(train_X[test_index]))\n",
    "    bst = xgb.train(param,  dtrain, int(num_round), verbose_eval=1)\n",
    "    y_valid_pred = np.round(bst.predict(dvalid))\n",
    "    validation_y = train_y[test_index]\n",
    "\n",
    "    acc.append(np.mean(y_valid_pred == np.array(validation_y)))\n",
    "    roc_auc.append(roc_auc_score(np.array(validation_y), bst.predict(dvalid)))\n",
    "    mcc.append(matthews_corrcoef(np.array(validation_y), y_valid_pred))\n",
    "    \n",
    "print(acc, roc_auc, mcc)\n",
    "acc_cv_esm1b_ts_ecfp = acc\n",
    "mcc_cv_esm1b_ts_ecfp = mcc\n",
    "roc_auc_cv_esm1b_ts_ecfp = roc_auc\n",
    "\n",
    "dtrain = xgb.DMatrix(np.array(train_X), weight = weights, label = np.array(train_y),\n",
    "                feature_names= feature_names)\n",
    "dtest = xgb.DMatrix(np.array(test_X), label = np.array(test_y),\n",
    "                    feature_names= feature_names)\n",
    "\n",
    "evallist = [(dtrain, \"train\"), (dtest, \"test\")]\n",
    "\n",
    "bst = xgb.train(param,  dtrain, int(num_round))#, evallist)\n",
    "\n",
    "y_test_pred = np.round(bst.predict(dtest))\n",
    "acc_test_esm1b_ts_ecfp = np.mean(y_test_pred == np.array(test_y))\n",
    "roc_auc_test_esm1b_ts_ecfp = roc_auc_score(np.array(test_y), bst.predict(dtest))\n",
    "mcc_test_esm1b_ts_ecfp = matthews_corrcoef(np.array(test_y), y_test_pred)\n",
    "print(\"Accuracy on test set: %s, ROC-AUC score for test set: %s, MCC: %s\"  % (acc_test_esm1b_ts_ecfp,\n",
    "                                                                              roc_auc_test_esm1b_ts_ecfp,\n",
    "                                                                              mcc_test_esm1b_ts_ecfp))\n",
    "data_test[\"y_pred_ECFP_esm1b_ts\"] = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Testing for statistical significance in model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_pred = pd.read_csv(join(\"..\", \"..\", \"data\", \"transporter_substrate_pairs\", \"df_UID_MID_test_with_pred.csv\"))\n",
    "data_test[\"y_pred_ChemBERTa_ESM1b\"] = df_test_pred[\"pred\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "\n",
    "def mc_nemar_test(y_true, y_pred1, y_pred2):\n",
    "    n00, n01, n10, n11 = 0,0,0,0\n",
    "    for i,y in enumerate(y_true):\n",
    "        if y == y_pred1[i]:\n",
    "            if y == y_pred2[i]:\n",
    "                n11 +=1\n",
    "            else:\n",
    "                n10 +=1\n",
    "        else:\n",
    "            if y == y_pred2[i]:\n",
    "                n01 +=1\n",
    "            else:\n",
    "                n00 +=1\n",
    "    \n",
    "    data = [[n00, n01],\n",
    "        [n10, n11]]\n",
    "    \n",
    "    significance_value = 0.05\n",
    "\n",
    "    # McNemar's Test with the continuity correction\n",
    "    test = mcnemar(data, exact=False)   \n",
    "    if test.pvalue < significance_value:\n",
    "        print(\"Reject Null hypotesis. p-value = %d\" % test.pvalue)\n",
    "    else:\n",
    "        print(\"Fail to reject Null hypotesis. p-value = %d\" % test.pvalue)\n",
    "    return(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = mc_nemar_test(y_true = np.array(data_test[\"outcome\"]),\n",
    "              y_pred1 = np.round(np.array(data_test[\"y_pred_ECFP_ESM1b\"])),\n",
    "              y_pred2 = np.round(np.array(data_test[\"y_pred_ChemBERTa_ESM1b\"])))\n",
    "print(test.pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transporter = pd.read_pickle(join(\"..\", \"..\", \"data\", \"Transporter_merged.pkl\"))\n",
    "\n",
    "data_test[\"Source\"] = \"\"\n",
    "\n",
    "UIDs = list(set(data_test[\"Uniprot ID\"]))\n",
    "for UID in UIDs:\n",
    "    help_df = df_transporter.loc[df_transporter[\"Uniprot ID\"] == UID]\n",
    "    if np.mean(help_df[\"GOA\"]) == 1:\n",
    "        data_test[\"Source\"].loc[data_test[\"Uniprot ID\"] == UID] = \"GOA\"\n",
    "    elif np.mean(help_df[\"TCDB\"]) == 1:\n",
    "        data_test[\"Source\"].loc[data_test[\"Uniprot ID\"] == UID] = \"TCDB\"\n",
    "    elif np.mean(help_df[\"SWISS\"]) == 1:\n",
    "         data_test[\"Source\"].loc[data_test[\"Uniprot ID\"] == UID] = \"UniProt\"\n",
    "            \n",
    "            \n",
    "for source in [\"GOA\", \"UniProt\"]:\n",
    "    help_df = data_test.loc[data_test[\"Source\"] == source]\n",
    "    y_test_pred, test_y = np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]), np.array(help_df[\"outcome\"])\n",
    "    mean_ident = np.mean(help_df[\"max_ident\"])\n",
    "    acc = np.mean(np.round(y_test_pred) == np.array(test_y))\n",
    "    roc_auc = roc_auc_score(np.array(test_y), y_test_pred)\n",
    "    mcc = matthews_corrcoef(np.array(test_y), np.round(y_test_pred))\n",
    "    \n",
    "    print(source, len(test_y), acc, roc_auc, mcc, mean_ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_source = {\"GOA\": \"navy\", \"TCDB\" : \"red\", \"UniProt\" : \"grey\"}\n",
    "\n",
    "splits = [\"10-30%\", \"50-70%\", \"90-100%\"]\n",
    "lower_bound = [10,40,70]\n",
    "upper_bound = [40,70,100]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,12))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "for source in [  \"UniProt\",  \"GOA\"]:\n",
    "    accuracies = []\n",
    "    MCCs = []\n",
    "    n_data_points = []\n",
    "    for i, split in enumerate(splits):\n",
    "        help_df = data_test.loc[data_test[\"Source\"] == source]\n",
    "        help_df = help_df.loc[help_df[\"max_ident\"]> lower_bound[i]]\n",
    "        help_df = help_df.loc[help_df[\"max_ident\"]<= upper_bound[i]]\n",
    "        y_true = np.array(help_df[\"outcome\"])\n",
    "        y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "        acc =  np.mean(y_pred == np.array(y_true))\n",
    "        mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "        accuracies.append(acc), MCCs.append(mcc)\n",
    "        n_data_points.append(len(y_pred))\n",
    "\n",
    "        if i ==0:\n",
    "            plt.scatter(-1, MCCs[i], color =color_source[source], s=100, label = source)\n",
    "            circle = plt.Circle((i/3, MCCs[i]), np.sqrt(len(help_df))/1500, color = color_source[source], fill = True)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "            #ax.annotate(n_data_points[i], (i-0.3, MCCs[i]-0.1), fontsize=20, c= color_source[source], weight = \"bold\")\n",
    "        else:\n",
    "            #ax.annotate(n_data_points[i], (i-0.38, MCCs[i]-0.1), fontsize=20, c= color_source[source], weight = \"bold\")\n",
    "            circle = plt.Circle((i/3, MCCs[i]), np.sqrt(len(help_df))/1500, color = color_source[source], fill = True)\n",
    "            ax.add_artist(circle)\n",
    "            \n",
    "    plt.plot(np.array(range(len(splits)))/3, MCCs, c= color_source[source], linewidth=2)\n",
    "\n",
    "\n",
    "\n",
    "ticks2 = np.array(range(len(splits)))/3\n",
    "labs = splits\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=5, rotation = 0)\n",
    "\n",
    "plt.ylim((-0.1,1.))\n",
    "plt.xlim((-0.1, 1.))\n",
    "\n",
    "plt.ylabel('MCC')\n",
    "plt.xlabel('Protein sequence identity')\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.1)\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"MCC_for_different_sources.svg\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [\"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "lower_bound = [10,20,30,40,50,60,70,80,90]\n",
    "upper_bound = [20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,12))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "for source in [\"GOA\", \"UniProt\"]:\n",
    "    accuracies = []\n",
    "    MCCs = []\n",
    "    n_data_points = []\n",
    "    for i, split in enumerate(splits):\n",
    "        help_df = data_test.loc[data_test[\"Source\"] == source]\n",
    "        help_df = help_df.loc[help_df[\"max_ident\"]> lower_bound[i]]\n",
    "        help_df = help_df.loc[help_df[\"max_ident\"]<= upper_bound[i]]\n",
    "        y_true = np.array(help_df[\"outcome\"])\n",
    "        y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "        acc =  np.mean(y_pred == np.array(y_true))\n",
    "        mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "        accuracies.append(acc), MCCs.append(mcc)\n",
    "        n_data_points.append(len(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "        if i ==0:\n",
    "            plt.scatter(-1, MCCs[i], color =color_source[source], s=100, label = source)\n",
    "            circle = plt.Circle((i/10, MCCs[i]), np.sqrt(len(help_df))/2000, color = color_source[source], fill = True)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "            #ax.annotate(n_data_points[i], (i-0.3, MCCs[i]-0.1), fontsize=20, c= color_source[source], weight = \"bold\")\n",
    "        else:\n",
    "            #ax.annotate(n_data_points[i], (i-0.38, MCCs[i]-0.1), fontsize=20, c= color_source[source], weight = \"bold\")\n",
    "            circle = plt.Circle((i/10, MCCs[i]), np.sqrt(len(help_df))/2000, color = color_source[source], fill = True)\n",
    "            ax.add_artist(circle)\n",
    "\n",
    "    plt.plot(np.array(range(len(splits)))/10, MCCs, c= color_source[source], linewidth=2)\n",
    "\n",
    "ticks2 = np.array(range(len(splits)))/10\n",
    "labs = splits\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 60)\n",
    "\n",
    "plt.ylim((-0.1,1.1))\n",
    "plt.xlim((-0.1, 1.1))\n",
    "\n",
    "plt.ylabel('MCC')\n",
    "plt.xlabel('Protein sequence identity')\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.33)\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC curves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_esm1b_ecfp =  np.array(data_test[\"y_pred_ECFP_ESM1b\"])\n",
    "test_y_esm1b_ecfp =  np.array(data_test[\"outcome\"])\n",
    "\n",
    "y_test_pred_esm1b_ts_ecfp =  np.array(data_test[\"y_pred_ECFP_esm1b_ts\"])\n",
    "test_y_esm1b_ts_ecfp =  np.array(data_test[\"outcome\"])\n",
    "\n",
    "y_test_pred_esm1b_chemberta =  np.array(data_test[\"y_pred_ChemBERTa_ESM1b\"])\n",
    "test_y_esm1b_chemberta =  np.array(data_test[\"outcome\"])\n",
    "\n",
    "y_test_pred_esm1b_ts_chemberta =  np.array(data_test[\"y_pred_chemberta_esm1b_ts\"])\n",
    "test_y_esm1b_ts_chemberta =  np.array(data_test[\"outcome\"])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (8,8))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "fpr_esm1b_ecfp, tpr_esm1b_ecfp, threshold = metrics.roc_curve(test_y_esm1b_ecfp, y_test_pred_esm1b_ecfp)\n",
    "roc_auc_esm1b_ecfp = metrics.auc(fpr_esm1b_ecfp, tpr_esm1b_ecfp)\n",
    "\n",
    "fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp, threshold = metrics.roc_curve(test_y_esm1b_ts_ecfp, y_test_pred_esm1b_ts_ecfp)\n",
    "roc_auc_esm1b_ts_ecfp = metrics.auc(fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp)\n",
    "\n",
    "\n",
    "fpr_esm1b_chemberta, tpr_esm1b_chemberta, threshold = metrics.roc_curve(test_y_esm1b_chemberta, y_test_pred_esm1b_chemberta)\n",
    "roc_auc_esm1b_chemberta = metrics.auc(fpr_esm1b_chemberta, tpr_esm1b_chemberta)\n",
    "\n",
    "fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta, threshold = metrics.roc_curve(test_y_esm1b_ts_chemberta, y_test_pred_esm1b_ts_chemberta)\n",
    "roc_auc_esm1b_ts_chemberta = metrics.auc(fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta)\n",
    "\n",
    "#plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_esm1b_chemberta, tpr_esm1b_chemberta, 'black', label = 'AUC (ESM-1b + ChemBERTa) = %0.3f' % roc_auc_esm1b_chemberta, linewidth=2.0)\n",
    "plt.plot(fpr_esm1b_ecfp, tpr_esm1b_ecfp, 'magenta', label = 'AUC (ESM-1b + ECFP) = %0.3f' % roc_auc_esm1b_ecfp, linewidth=2.0)\n",
    "plt.plot(fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta, 'blue', label = 'AUC (ESM-$1b_{ts}$ + ChemBERTa) = %0.3f' % roc_auc_esm1b_ts_chemberta, linewidth=2.0)\n",
    "plt.plot(fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp, 'red', label = 'AUC (ESM-$1b_{ts}$ + ECFP) = %0.3f' % roc_auc_esm1b_ts_ecfp, linewidth=2.0)\n",
    "plt.plot(fpr_esm1b_chemberta, tpr_esm1b_chemberta, 'black', linewidth=2.0)\n",
    "\n",
    "\n",
    "\n",
    "ax.locator_params(axis=\"y\", nbins=5)\n",
    "ax.locator_params(axis=\"x\", nbins=5)\n",
    "\n",
    "plt.legend(loc = 'lower right', fontsize =20)\n",
    "plt.plot([0, 1], [0, 1],'--')\n",
    "eps = 0.01\n",
    "plt.xlim([0-eps, 1+eps])\n",
    "plt.ylim([0-eps, 1+eps])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"ROC_curves.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (4,4))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "fpr_esm1b_ecfp, tpr_esm1b_ecfp, threshold = metrics.roc_curve(test_y_esm1b_ecfp, y_test_pred_esm1b_ecfp)\n",
    "roc_auc_esm1b_ecfp = metrics.auc(fpr_esm1b_ecfp, tpr_esm1b_ecfp)\n",
    "\n",
    "fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp, threshold = metrics.roc_curve(test_y_esm1b_ts_ecfp, y_test_pred_esm1b_ts_ecfp)\n",
    "roc_auc_esm1b_ts_ecfp = metrics.auc(fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp)\n",
    "\n",
    "\n",
    "fpr_esm1b_chemberta, tpr_esm1b_chemberta, threshold = metrics.roc_curve(test_y_esm1b_chemberta, y_test_pred_esm1b_chemberta)\n",
    "roc_auc_esm1b_chemberta = metrics.auc(fpr_esm1b_chemberta, tpr_esm1b_chemberta)\n",
    "\n",
    "fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta, threshold = metrics.roc_curve(test_y_esm1b_ts_chemberta, y_test_pred_esm1b_ts_chemberta)\n",
    "roc_auc_esm1b_ts_chemberta = metrics.auc(fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta)\n",
    "\n",
    "#plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr_esm1b_ecfp, tpr_esm1b_ecfp, 'magenta', label = 'AUC (ESM-1b/ECFP) = %0.3f' % roc_auc_esm1b_ecfp, linewidth=3.0)\n",
    "plt.plot(fpr_esm1b_ts_ecfp, tpr_esm1b_ts_ecfp, 'red', label = 'AUC (ESM-$1b_{ts}$/ECFP) = %0.3f' % roc_auc_esm1b_ts_ecfp, linewidth=3.0)\n",
    "\n",
    "plt.plot(fpr_esm1b_ts_chemberta, tpr_esm1b_ts_chemberta, 'blue', label = 'AUC (ESM-$1b_{ts}$/chemberta) = %0.3f' % roc_auc_esm1b_ts_chemberta, linewidth=3.0)\n",
    "plt.plot(fpr_esm1b_chemberta, tpr_esm1b_chemberta, 'black', label = 'AUC (ESM-1b/chemberta) = %0.3f' % roc_auc_esm1b_chemberta, linewidth=3.0)\n",
    "\n",
    "\n",
    "\n",
    "ticks2 = np.array([0.01,0.03, 0.05])\n",
    "labs = [ \"0.01\", \"0.03\", \"0.05\"]\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=10, rotation = 0)\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1],'--')\n",
    "eps = 0.5*1e-3\n",
    "plt.xlim([0-eps, 0.055])\n",
    "plt.ylim([0-eps, 0.85])#1+eps])\n",
    "ax.locator_params(axis=\"y\", nbins=4)\n",
    "#ax.locator_params(axis=\"x\", nbins=3)\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"ROC_curves_inset.png\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting prediction distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = np.array(data_test[\"y_pred_ChemBERTa_ESM1b\"])\n",
    "test_y = np.array(data_test[\"outcome\"])\n",
    "wrong_predictions = [np.round(y_test_pred[i]) != test_y[i] for i in range(len(test_y))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,6))\n",
    "#plt.title(\"Distribution of predicted probabilities\", fontsize= 30, y= 1)\n",
    "y_test_wrong = list(y_test_pred[wrong_predictions])\n",
    "y_test_pred_copy =list(y_test_pred.copy())\n",
    "y_test_wrong.append(0), y_test_pred_copy.append(0) ,y_test_wrong.append(1), y_test_pred_copy.append(1)\n",
    "\n",
    "plt.hist(y_test_pred_copy, density = False, bins= 30, rwidth = 0.8, color= \"navy\", label = \"true predictions\")\n",
    "plt.hist(y_test_wrong, density = False, bins= 30, rwidth = 0.8, color= \"red\", label = \"false predictions\")\n",
    "\n",
    "\n",
    "plt.xlabel('Prediction score')\n",
    "plt.ylabel('Count')\n",
    "ax.yaxis.set_label_coords(-0.13, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "ticks1 = [1000,2000]\n",
    "ax.set_yticks(ticks1)\n",
    "ax.set_yticklabels([\"1000\", \"2000\"])\n",
    "ax.tick_params(axis='x', which=\"major\", length=10)\n",
    "\n",
    "plt.legend(loc = \"upper center\", fontsize=18)\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"hist_predicted_values.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = [list(wrong_predictions)[i] and list(y_test_pred<0.8)[i] and list(y_test_pred >0.2)[i] for i in range(len(wrong_predictions))]\n",
    "y_test_wrong = list(y_test_pred[select])\n",
    "select = [list(y_test_pred<0.8)[i] and list(y_test_pred >0.2)[i] for i in range(len(y_test_pred))]\n",
    "y_test_pred_subset = list(y_test_pred[select])\n",
    "y_test_wrong.append(0.2), y_test_pred_subset.append(0.2) ,y_test_wrong.append(0.8), y_test_pred_subset.append(0.8)\n",
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,6))\n",
    "#plt.title(\"Distribution of predicted probabilities\", fontsize= 30, y= 1)\n",
    "\n",
    "plt.hist(y_test_pred_subset, density = False, bins= 30, rwidth = 0.8, color= \"navy\", label = \"true predictions\")\n",
    "plt.hist(y_test_wrong, density = False, bins= 30, rwidth = 0.8, color= \"red\", label = \"false predictions\")\n",
    "\n",
    "ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "ax.tick_params(axis='x', which=\"major\", length=10)\n",
    "\n",
    "ticks1 = [0,100]\n",
    "ax.set_yticks(ticks1)\n",
    "ax.set_yticklabels([\"0\", \"100\"])\n",
    "\n",
    "plt.xlim([0.2, 0.80])\n",
    "plt.ylim([0, 130])\n",
    "#ax.get_yaxis().set_visible(False)\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"hist_predicted_values_inset.png\"))\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_confidence = np.bitwise_or(y_test_pred <0.4, y_test_pred >0.6)\n",
    "np.mean(high_confidence), np.mean(np.round(y_test_pred[high_confidence]) == test_y[high_confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1- np.mean(high_confidence), np.mean(np.round(y_test_pred[~ high_confidence]) == test_y[~ high_confidence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (12,8))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "splits = [\"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "lower_bound = [10,20,30,40,50,60,70,80,90]\n",
    "upper_bound = [20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "accuracies = []\n",
    "MCCs = []\n",
    "n_data_points = []\n",
    "for i, split in enumerate(splits):\n",
    "    \n",
    "    help_df = data_test.loc[data_test[\"max_ident\"]> lower_bound[i]]\n",
    "    help_df = help_df.loc[help_df[\"max_ident\"]<= upper_bound[i]]\n",
    "    y_true = np.array(help_df[\"outcome\"])\n",
    "    y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "    acc =  np.mean(y_pred == np.array(y_true))\n",
    "    mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "    accuracies.append(acc), MCCs.append(mcc)\n",
    "    n_data_points.append(len(y_pred))\n",
    "    print(lower_bound[i], upper_bound[i], acc, mcc)\n",
    "    \n",
    "sub_bins = list(range(9))\n",
    "    \n",
    "#plt.bar(sub_bins, height = MCCs,  color= \"navy\")\n",
    "\n",
    "\n",
    "for i in range(9):\n",
    "    plt.scatter(i, MCCs[i], c='navy', marker=\"o\", linewidths= 8, label =\"KCATpred\")\n",
    "    ax.annotate(n_data_points[i], (i-0.3, MCCs[i]+0.03), fontsize=20, c= \"black\", weight = \"bold\")\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ticks2 = np.array(range(len(splits)))\n",
    "labs = splits\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 60)\n",
    "\n",
    "plt.ylim((0.0,1.1))\n",
    "plt.xlim((-0.4, 8.2))\n",
    "\n",
    "plt.ylabel('MCC')\n",
    "plt.xlabel('Protein sequence identity')\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.33)\n",
    "\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"MCC_prot_seq_ident.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (12,8))\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "splits = [\"10-20%\", \"20-30%\", \"30-40%\", \"40-50%\", \"50-60%\", \"60-70%\", \"70-80%\", \"80-90%\", \"90-100%\"]\n",
    "lower_bound = [10,20,30,40,50,60,70,80,90]\n",
    "upper_bound = [20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "accuracies = []\n",
    "MCCs = []\n",
    "n_data_points = []\n",
    "for i, split in enumerate(splits):\n",
    "    \n",
    "    help_df = data_test.loc[data_test[\"max_ident\"]> lower_bound[i]]\n",
    "    help_df = help_df.loc[help_df[\"max_ident\"]<= upper_bound[i]]\n",
    "    y_true = np.array(help_df[\"outcome\"])\n",
    "    y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "    acc =  np.mean(y_pred == np.array(y_true))\n",
    "    mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "    accuracies.append(acc), MCCs.append(mcc)\n",
    "    n_data_points.append(len(y_pred))\n",
    "    \n",
    "sub_bins = list(range(9))\n",
    "    \n",
    "plt.bar(sub_bins, height = accuracies,  color= \"navy\")\n",
    "\n",
    "for i in range(9):\n",
    "    if n_data_points[i]<1000:\n",
    "        ax.annotate(n_data_points[i], (i-0.3, accuracies[i]-0.1), fontsize=20, c= \"white\", weight = \"bold\")\n",
    "    else:\n",
    "        ax.annotate(n_data_points[i], (i-0.38, accuracies[i]-0.1), fontsize=20, c= \"white\", weight = \"bold\")\n",
    "\n",
    "\n",
    "ticks2 = np.array(range(len(splits)))\n",
    "labs = splits\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 60)\n",
    "\n",
    "plt.ylim((0.0,1.1))\n",
    "#plt.xlim((-0.2, 9.6))\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Protein sequence identity')\n",
    "ax.yaxis.set_label_coords(-0.1, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.33)\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"Acc_prot_seq_ident.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df = data_test.loc[data_test[\"max_ident\"]> 0]\n",
    "help_df = help_df.loc[help_df[\"max_ident\"]< 40]\n",
    "y_true = np.array(help_df[\"outcome\"])\n",
    "y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "acc =  np.mean(y_pred == np.array(y_true))\n",
    "mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "\n",
    "acc, mcc, len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df = data_test.loc[data_test[\"max_ident\"]> 50]\n",
    "y_true = np.array(help_df[\"outcome\"])\n",
    "y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "acc =  np.mean(y_pred == np.array(y_true))\n",
    "mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "\n",
    "acc, mcc, len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test[\"sub_train_count\"] = np.nan\n",
    "\n",
    "train_subs = list(data_train[\"molecule ID\"].loc[data_train[\"outcome\"] == 1])\n",
    "for ind in data_test.index:\n",
    "    sub = data_test[\"molecule ID\"][ind]\n",
    "    data_test[\"sub_train_count\"][ind] = sum([sub == train_sub for train_sub in train_subs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_bins = list(range(11))\n",
    "MCCs = []\n",
    "n_data_points = []\n",
    "for k in sub_bins:\n",
    "    df_help = data_test.loc[data_test[\"sub_train_count\"] == k]\n",
    "    pred = np.round(np.array(df_help[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "    true = np.array(df_help[\"outcome\"])\n",
    "    mcc = matthews_corrcoef(true, pred)\n",
    "    MCCs.append(mcc)\n",
    "    print(k, mcc, len(pred))\n",
    "    n_data_points.append(len(pred))\n",
    "\n",
    "df_help = data_test.loc[data_test[\"sub_train_count\"] > 10]\n",
    "pred = np.round(np.array(df_help[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "true = np.array(df_help[\"outcome\"])\n",
    "mcc = np.mean(pred == true)\n",
    "n_data_points.append(len(pred))\n",
    "print(\">10\", mcc, len(pred))\n",
    "MCCs.append(mcc)\n",
    "sub_bins.append(11)\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,6))\n",
    "#plt.title(\"Distribution of predicted probabilities\", fontsize= 30, y= 1)\n",
    "\n",
    "#plt.bar(sub_bins, height = MCCs,  color= \"navy\")\n",
    "\n",
    "for i in range(12):\n",
    "    plt.scatter(i, MCCs[i], c='navy', marker=\"o\", linewidths= 8, label =\"KCATpred\")\n",
    "    ax.annotate(n_data_points[i], (i-0.3, MCCs[i]+0.03), fontsize=20, c= \"black\", weight = \"bold\")\n",
    "\n",
    "plt.xlabel('Number of positive samples with \\n identical substrates in the training set')\n",
    "plt.ylabel('MCC')\n",
    "ax.yaxis.set_label_coords(-0.12, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "ticks2 = np.array(list(range(11)) + [11.2])\n",
    "labs = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \">10\"]\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "plt.ylim((-0.1,1))\n",
    "plt.xlim((-0.4,11.5))\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"MCC_num_subs.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sub_bins = list(range(11))\n",
    "MCCs = []\n",
    "for k in sub_bins:\n",
    "    df_help = data_test.loc[data_test[\"sub_train_count\"] == k]\n",
    "    pred = np.round(np.array(df_help[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "    true = np.array(df_help[\"outcome\"])\n",
    "    mcc = np.mean(true == pred)\n",
    "    MCCs.append(mcc)\n",
    "    print(k, mcc, len(pred))\n",
    "\n",
    "df_help = data_test.loc[data_test[\"sub_train_count\"] > 10]\n",
    "pred = np.round(np.array(df_help[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "true = np.array(df_help[\"outcome\"])\n",
    "mcc = np.mean(pred == true)\n",
    "print(\">10\", mcc, len(pred))\n",
    "MCCs.append(mcc)\n",
    "sub_bins.append(11)\n",
    "\n",
    "\n",
    "plt.rcParams.update({'font.size': 28})\n",
    "\n",
    "#plt.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(figsize= (12,6))\n",
    "#plt.title(\"Distribution of predicted probabilities\", fontsize= 30, y= 1)\n",
    "\n",
    "plt.bar(sub_bins, height = MCCs,  color= \"navy\")\n",
    "\n",
    "for i in range(12):\n",
    "    if i ==0:\n",
    "        ax.annotate(n_data_points[i], (i-0.18, 0.05), fontsize=22, c= \"white\", weight = \"bold\", rotation = 90)\n",
    "    else:\n",
    "        ax.annotate(n_data_points[i], (i-0.18, 0.05), fontsize=22, c= \"white\", weight = \"bold\", rotation = 90)\n",
    "\n",
    "plt.xlabel('Number of positive samples with \\n identical substrates in the training set')\n",
    "plt.ylabel('Accuracy')\n",
    "ax.yaxis.set_label_coords(-0.08, 0.5)\n",
    "ax.xaxis.set_label_coords(0.5,-0.13)\n",
    "\n",
    "ticks2 = np.array(list(range(11)) + [11.2])\n",
    "labs = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\", \">10\"]\n",
    "ax.set_xticks(ticks2)\n",
    "ax.set_xticklabels(labs,  y= -0.03, fontsize=26)\n",
    "ax.tick_params(axis='x', length=0, rotation = 0)\n",
    "\n",
    "plt.ylim((0,1))\n",
    "plt.savefig(join(\"..\", \"..\", \"figures\", \"acc_num_subs.png\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df = data_test.loc[data_test[\"sub_train_count\"]> 0]\n",
    "\n",
    "y_true = np.array(help_df[\"outcome\"])\n",
    "y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "acc =  np.mean(y_pred == np.array(y_true))\n",
    "mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "\n",
    "acc, mcc, len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_df = data_test.loc[data_test[\"sub_train_count\"] == 0]\n",
    "\n",
    "y_true = np.array(help_df[\"outcome\"])\n",
    "y_pred = np.round(np.array(help_df[\"y_pred_ChemBERTa_ESM1b\"]))\n",
    "acc =  np.mean(y_pred == np.array(y_true))\n",
    "mcc = matthews_corrcoef(np.array(y_true), y_pred)\n",
    "\n",
    "acc, mcc, len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(np.array(data_test[\"outcome\"]), np.round(np.array(data_test[\"y_pred_ChemBERTa_ESM1b\"]))).ravel()\n",
    "print(\"True positive rate: %s\" % (tp/(tp+fn)))\n",
    "print(\"False positive rate: %s\" % (fp/(tp+fn)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
